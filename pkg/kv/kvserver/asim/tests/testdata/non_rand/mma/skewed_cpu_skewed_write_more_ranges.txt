# This test is similar to skewed_cpu_skewed_write.txt, but with more ranges 300. 
# To have the same amount of total load, bytes per range is reduced to 26 MiB.
# 
# Expected outcome: The allocator should rebalance both cpu and write load across
# all stores, with mma achieving better results than sma. 
gen_cluster nodes=6 node_cpu_rate_capacity=5000000000
----

# The placement will be skewed, s.t. n1/s1, n2/s2 and n3/s3 will have all the
# replicas initially and n1/s1 will have every lease. Each range is initially
# 26 MiB.
gen_ranges ranges=300 min_key=1 max_key=10000 placement_type=replica_placement bytes=26843545
{s1,s2,s3}:1
----
{s1:*,s2,s3}:1

gen_load rate=1000 rw_ratio=1.0 request_cpu_per_access=5000000 min_key=1 max_key=10000
----

# Write only workload, which generates little CPU and 100_000 (x replication
# factor) write bytes per second over the second half of the keyspace.
gen_ranges ranges=300 min_key=10001 max_key=20000 placement_type=replica_placement bytes=26843545
{s4,s5,s6}:1
----
{s4:*,s5,s6}:1

gen_load rate=20000 rw_ratio=0 min_block=1000 max_block=1000 raft_cpu_per_write=1 min_key=10001 max_key=20000
----

setting split_queue_enabled=false
----

eval duration=75m samples=1 seed=42 cfgs=(mma-only,mma-count) metrics=(cpu,cpu_util,write_bytes_per_second,replicas,leases)
----
cpu#1: last:  [s1=905856280, s2=907512676, s3=904494952, s4=757899339, s5=762477957, s6=756984494] (stddev=73441866.78, mean=832537616.33, sum=4995225698)
cpu#1: thrash_pct: [s1=9%, s2=55%, s3=53%, s4=26%, s5=27%, s6=26%]  (sum=197%)
cpu_util#1: last:  [s1=0.18, s2=0.18, s3=0.18, s4=0.15, s5=0.15, s6=0.15] (stddev=0.01, mean=0.17, sum=1)
cpu_util#1: thrash_pct: [s1=9%, s2=55%, s3=53%, s4=26%, s5=27%, s6=26%]  (sum=197%)
leases#1: first: [s1=300, s2=0, s3=0, s4=300, s5=0, s6=0] (stddev=141.42, mean=100.00, sum=600)
leases#1: last:  [s1=55, s2=129, s3=115, s4=212, s5=43, s6=46] (stddev=60.28, mean=100.00, sum=600)
leases#1: thrash_pct: [s1=0%, s2=23%, s3=19%, s4=34%, s5=0%, s6=0%]  (sum=77%)
replicas#1: first: [s1=300, s2=300, s3=300, s4=300, s5=300, s6=300] (stddev=0.00, mean=300.00, sum=1800)
replicas#1: last:  [s1=310, s2=427, s3=432, s4=212, s5=208, s6=211] (stddev=98.13, mean=300.00, sum=1800)
replicas#1: thrash_pct: [s1=58%, s2=24%, s3=21%, s4=36%, s5=34%, s6=36%]  (sum=209%)
write_bytes_per_second#1: last:  [s1=6280392, s2=10498642, s3=10496211, s4=10961853, s5=10895559, s6=10887167] (stddev=1675536.72, mean=10003304.00, sum=60019824)
write_bytes_per_second#1: thrash_pct: [s1=1%, s2=9%, s3=9%, s4=3%, s5=70%, s6=95%]  (sum=187%)
artifacts[mma-only]: 91d6e66cfcb8011
==========================
cpu#1: last:  [s1=791551814, s2=775866971, s3=773712953, s4=874767691, s5=894297562, s6=890714250] (stddev=53740956.27, mean=833485206.83, sum=5000911241)
cpu#1: thrash_pct: [s1=20%, s2=70%, s3=79%, s4=47%, s5=30%, s6=38%]  (sum=285%)
cpu_util#1: last:  [s1=0.16, s2=0.16, s3=0.15, s4=0.17, s5=0.18, s6=0.18] (stddev=0.01, mean=0.17, sum=1)
cpu_util#1: thrash_pct: [s1=20%, s2=70%, s3=79%, s4=47%, s5=30%, s6=38%]  (sum=285%)
leases#1: first: [s1=300, s2=0, s3=0, s4=300, s5=0, s6=0] (stddev=141.42, mean=100.00, sum=600)
leases#1: last:  [s1=101, s2=101, s3=104, s4=98, s5=99, s6=97] (stddev=2.31, mean=100.00, sum=600)
leases#1: thrash_pct: [s1=63%, s2=94%, s3=81%, s4=86%, s5=77%, s6=77%]  (sum=478%)
replicas#1: first: [s1=300, s2=300, s3=300, s4=300, s5=300, s6=300] (stddev=0.00, mean=300.00, sum=1800)
replicas#1: last:  [s1=311, s2=311, s3=310, s4=292, s5=284, s6=292] (stddev=11.00, mean=300.00, sum=1800)
replicas#1: thrash_pct: [s1=485%, s2=698%, s3=604%, s4=591%, s5=585%, s6=561%]  (sum=3524%)
write_bytes_per_second#1: last:  [s1=7591987, s2=10231682, s3=9706819, s4=10698850, s5=10961520, s6=10827492] (stddev=1157278.21, mean=10003058.33, sum=60018350)
write_bytes_per_second#1: thrash_pct: [s1=63%, s2=91%, s3=71%, s4=168%, s5=169%, s6=180%]  (sum=743%)
artifacts[mma-count]: 1375036a6d9d5dfa
==========================
